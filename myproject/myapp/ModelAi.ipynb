{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in target variable:\n",
      "Fertilizer\n",
      "Urea                  130\n",
      "DAP                   122\n",
      "28-28                  85\n",
      "20-20                  70\n",
      "14-35-14               70\n",
      "17-17-17               35\n",
      "10/26/2026             35\n",
      "TSP                    28\n",
      "14-14-14               16\n",
      "15-15-15               16\n",
      "10/10/2010             16\n",
      "Superphosphate         12\n",
      "Potassium sulfate.     12\n",
      "Potassium chloride      4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Percentage distribution:\n",
      "Fertilizer\n",
      "Urea                  19.969278\n",
      "DAP                   18.740399\n",
      "28-28                 13.056836\n",
      "20-20                 10.752688\n",
      "14-35-14              10.752688\n",
      "17-17-17               5.376344\n",
      "10/26/2026             5.376344\n",
      "TSP                    4.301075\n",
      "14-14-14               2.457757\n",
      "15-15-15               2.457757\n",
      "10/10/2010             2.457757\n",
      "Superphosphate         1.843318\n",
      "Potassium sulfate.     1.843318\n",
      "Potassium chloride     0.614439\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Training Logistic Regression...\n",
      "\n",
      "Detailed Classification Report for Logistic Regression:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "        10/10/2010       1.00      1.00      1.00         3\n",
      "        10/26/2026       1.00      1.00      1.00         7\n",
      "          14-14-14       1.00      1.00      1.00         3\n",
      "          14-35-14       1.00      1.00      1.00        14\n",
      "          15-15-15       1.00      1.00      1.00         3\n",
      "          17-17-17       1.00      1.00      1.00         7\n",
      "             20-20       1.00      1.00      1.00        14\n",
      "             28-28       1.00      1.00      1.00        17\n",
      "               DAP       0.95      0.80      0.87        25\n",
      "Potassium chloride       0.33      1.00      0.50         1\n",
      "Potassium sulfate.       0.50      0.33      0.40         3\n",
      "    Superphosphate       0.40      1.00      0.57         2\n",
      "               TSP       0.56      0.83      0.67         6\n",
      "              Urea       1.00      0.88      0.94        26\n",
      "\n",
      "          accuracy                           0.92       131\n",
      "         macro avg       0.84      0.92      0.85       131\n",
      "      weighted avg       0.94      0.92      0.92       131\n",
      "\n",
      "\n",
      "Training Decision Tree...\n",
      "\n",
      "Detailed Classification Report for Decision Tree:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "        10/10/2010       1.00      1.00      1.00         3\n",
      "        10/26/2026       1.00      1.00      1.00         7\n",
      "          14-14-14       1.00      1.00      1.00         3\n",
      "          14-35-14       1.00      1.00      1.00        14\n",
      "          15-15-15       1.00      1.00      1.00         3\n",
      "          17-17-17       1.00      1.00      1.00         7\n",
      "             20-20       1.00      1.00      1.00        14\n",
      "             28-28       1.00      1.00      1.00        17\n",
      "               DAP       1.00      1.00      1.00        25\n",
      "Potassium chloride       1.00      1.00      1.00         1\n",
      "Potassium sulfate.       1.00      1.00      1.00         3\n",
      "    Superphosphate       1.00      1.00      1.00         2\n",
      "               TSP       1.00      1.00      1.00         6\n",
      "              Urea       1.00      1.00      1.00        26\n",
      "\n",
      "          accuracy                           1.00       131\n",
      "         macro avg       1.00      1.00      1.00       131\n",
      "      weighted avg       1.00      1.00      1.00       131\n",
      "\n",
      "\n",
      "Training Random Forest...\n",
      "\n",
      "Detailed Classification Report for Random Forest:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "        10/10/2010       1.00      1.00      1.00         3\n",
      "        10/26/2026       1.00      1.00      1.00         7\n",
      "          14-14-14       1.00      1.00      1.00         3\n",
      "          14-35-14       1.00      1.00      1.00        14\n",
      "          15-15-15       1.00      1.00      1.00         3\n",
      "          17-17-17       1.00      1.00      1.00         7\n",
      "             20-20       1.00      1.00      1.00        14\n",
      "             28-28       1.00      1.00      1.00        17\n",
      "               DAP       1.00      1.00      1.00        25\n",
      "Potassium chloride       1.00      1.00      1.00         1\n",
      "Potassium sulfate.       1.00      1.00      1.00         3\n",
      "    Superphosphate       1.00      1.00      1.00         2\n",
      "               TSP       1.00      1.00      1.00         6\n",
      "              Urea       1.00      1.00      1.00        26\n",
      "\n",
      "          accuracy                           1.00       131\n",
      "         macro avg       1.00      1.00      1.00       131\n",
      "      weighted avg       1.00      1.00      1.00       131\n",
      "\n",
      "\n",
      "Training Gradient Boosting...\n",
      "\n",
      "Detailed Classification Report for Gradient Boosting:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "        10/10/2010       1.00      1.00      1.00         3\n",
      "        10/26/2026       1.00      1.00      1.00         7\n",
      "          14-14-14       1.00      1.00      1.00         3\n",
      "          14-35-14       1.00      1.00      1.00        14\n",
      "          15-15-15       1.00      1.00      1.00         3\n",
      "          17-17-17       1.00      1.00      1.00         7\n",
      "             20-20       1.00      1.00      1.00        14\n",
      "             28-28       1.00      1.00      1.00        17\n",
      "               DAP       1.00      1.00      1.00        25\n",
      "Potassium chloride       1.00      1.00      1.00         1\n",
      "Potassium sulfate.       1.00      1.00      1.00         3\n",
      "    Superphosphate       1.00      1.00      1.00         2\n",
      "               TSP       1.00      1.00      1.00         6\n",
      "              Urea       1.00      1.00      1.00        26\n",
      "\n",
      "          accuracy                           1.00       131\n",
      "         macro avg       1.00      1.00      1.00       131\n",
      "      weighted avg       1.00      1.00      1.00       131\n",
      "\n",
      "\n",
      "Training XGBoost...\n",
      "\n",
      "Detailed Classification Report for XGBoost:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "        10/10/2010       1.00      1.00      1.00         3\n",
      "        10/26/2026       1.00      1.00      1.00         7\n",
      "          14-14-14       1.00      1.00      1.00         3\n",
      "          14-35-14       1.00      1.00      1.00        14\n",
      "          15-15-15       1.00      1.00      1.00         3\n",
      "          17-17-17       1.00      1.00      1.00         7\n",
      "             20-20       1.00      1.00      1.00        14\n",
      "             28-28       1.00      1.00      1.00        17\n",
      "               DAP       1.00      1.00      1.00        25\n",
      "Potassium chloride       1.00      1.00      1.00         1\n",
      "Potassium sulfate.       1.00      1.00      1.00         3\n",
      "    Superphosphate       1.00      1.00      1.00         2\n",
      "               TSP       1.00      1.00      1.00         6\n",
      "              Urea       1.00      1.00      1.00        26\n",
      "\n",
      "          accuracy                           1.00       131\n",
      "         macro avg       1.00      1.00      1.00       131\n",
      "      weighted avg       1.00      1.00      1.00       131\n",
      "\n",
      "\n",
      "Training SVC...\n",
      "\n",
      "Detailed Classification Report for SVC:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "        10/10/2010       1.00      1.00      1.00         3\n",
      "        10/26/2026       1.00      1.00      1.00         7\n",
      "          14-14-14       1.00      1.00      1.00         3\n",
      "          14-35-14       1.00      1.00      1.00        14\n",
      "          15-15-15       1.00      1.00      1.00         3\n",
      "          17-17-17       1.00      1.00      1.00         7\n",
      "             20-20       1.00      1.00      1.00        14\n",
      "             28-28       1.00      1.00      1.00        17\n",
      "               DAP       1.00      0.92      0.96        25\n",
      "Potassium chloride       0.50      1.00      0.67         1\n",
      "Potassium sulfate.       1.00      1.00      1.00         3\n",
      "    Superphosphate       0.67      1.00      0.80         2\n",
      "               TSP       0.75      1.00      0.86         6\n",
      "              Urea       1.00      0.92      0.96        26\n",
      "\n",
      "          accuracy                           0.97       131\n",
      "         macro avg       0.92      0.99      0.95       131\n",
      "      weighted avg       0.98      0.97      0.97       131\n",
      "\n",
      "\n",
      "Model Comparison Results:\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Model                 Train Acc   Test Acc  Precision     Recall   F1 Score    CV Mean     CV Std\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Logistic Regression      0.9519     0.9160     0.9449     0.9160     0.9236     0.9309     0.0137\n",
      "Decision Tree            1.0000     1.0000     1.0000     1.0000     1.0000     1.0000     0.0000\n",
      "Random Forest            1.0000     1.0000     1.0000     1.0000     1.0000     1.0000     0.0000\n",
      "Gradient Boosting        1.0000     1.0000     1.0000     1.0000     1.0000     1.0000     0.0000\n",
      "XGBoost                  1.0000     1.0000     1.0000     1.0000     1.0000     1.0000     0.0000\n",
      "SVC                      0.9769     0.9695     0.9796     0.9695     0.9720     0.9646     0.0143\n",
      "\n",
      "Best performing model: Decision Tree\n",
      "F1 Score: 1.0000\n",
      "Test Accuracy: 1.0000\n",
      "\n",
      "Sample of Actual vs Predicted values:\n",
      "               Actual           Predicted  Correct\n",
      "0  Potassium sulfate.  Potassium sulfate.     True\n",
      "1                Urea                Urea     True\n",
      "2      Superphosphate      Superphosphate     True\n",
      "3                 DAP                 DAP     True\n",
      "4               20-20               20-20     True\n",
      "5                 DAP                 DAP     True\n",
      "6                 TSP                 TSP     True\n",
      "7          10/26/2026          10/26/2026     True\n",
      "8               28-28               28-28     True\n",
      "9                 DAP                 DAP     True\n",
      "\n",
      "Confusion Matrix:\n",
      "                    10/10/2010  10/26/2026  14-14-14  14-35-14  15-15-15  \\\n",
      "10/10/2010                   3           0         0         0         0   \n",
      "10/26/2026                   0           7         0         0         0   \n",
      "14-14-14                     0           0         3         0         0   \n",
      "14-35-14                     0           0         0        14         0   \n",
      "15-15-15                     0           0         0         0         3   \n",
      "17-17-17                     0           0         0         0         0   \n",
      "20-20                        0           0         0         0         0   \n",
      "28-28                        0           0         0         0         0   \n",
      "DAP                          0           0         0         0         0   \n",
      "Potassium chloride           0           0         0         0         0   \n",
      "Potassium sulfate.           0           0         0         0         0   \n",
      "Superphosphate               0           0         0         0         0   \n",
      "TSP                          0           0         0         0         0   \n",
      "Urea                         0           0         0         0         0   \n",
      "\n",
      "                    17-17-17  20-20  28-28  DAP  Potassium chloride  \\\n",
      "10/10/2010                 0      0      0    0                   0   \n",
      "10/26/2026                 0      0      0    0                   0   \n",
      "14-14-14                   0      0      0    0                   0   \n",
      "14-35-14                   0      0      0    0                   0   \n",
      "15-15-15                   0      0      0    0                   0   \n",
      "17-17-17                   7      0      0    0                   0   \n",
      "20-20                      0     14      0    0                   0   \n",
      "28-28                      0      0     17    0                   0   \n",
      "DAP                        0      0      0   25                   0   \n",
      "Potassium chloride         0      0      0    0                   1   \n",
      "Potassium sulfate.         0      0      0    0                   0   \n",
      "Superphosphate             0      0      0    0                   0   \n",
      "TSP                        0      0      0    0                   0   \n",
      "Urea                       0      0      0    0                   0   \n",
      "\n",
      "                    Potassium sulfate.  Superphosphate  TSP  Urea  \n",
      "10/10/2010                           0               0    0     0  \n",
      "10/26/2026                           0               0    0     0  \n",
      "14-14-14                             0               0    0     0  \n",
      "14-35-14                             0               0    0     0  \n",
      "15-15-15                             0               0    0     0  \n",
      "17-17-17                             0               0    0     0  \n",
      "20-20                                0               0    0     0  \n",
      "28-28                                0               0    0     0  \n",
      "DAP                                  0               0    0     0  \n",
      "Potassium chloride                   0               0    0     0  \n",
      "Potassium sulfate.                   3               0    0     0  \n",
      "Superphosphate                       0               2    0     0  \n",
      "TSP                                  0               0    6     0  \n",
      "Urea                                 0               0    0    26  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_support\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\rushi\\\\Desktop\\\\FertilizeWise\\\\FertWiseMergedMain.csv\")\n",
    "# First, let's analyze the class distribution\n",
    "print(\"Class distribution in target variable:\")\n",
    "print(df['Fertilizer'].value_counts())\n",
    "print(\"\\nPercentage distribution:\")\n",
    "print(df['Fertilizer'].value_counts(normalize=True) * 100)\n",
    "\n",
    "# First, identify categorical and numerical columns\n",
    "categorical_columns = ['Soil_Type', 'Crop_Type']\n",
    "numerical_columns = ['Temparature', 'Humidity', 'Moisture', 'Nitrogen', 'Potassium', 'Phosphorous']\n",
    "\n",
    "# Create preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_columns),\n",
    "        ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_columns)\n",
    "    ])\n",
    "\n",
    "# Prepare X and y\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df['Fertilizer'])\n",
    "X = df[numerical_columns + categorical_columns]\n",
    "\n",
    "# Split the data using stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Define models with class weight consideration\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, class_weight='balanced'),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42, class_weight='balanced'),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced'),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'XGBoost': XGBClassifier(n_estimators=100, random_state=42, scale_pos_weight=1),\n",
    "    'SVC': SVC(kernel='rbf', class_weight='balanced')\n",
    "}\n",
    "\n",
    "# Define custom cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Train and evaluate each model\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    try:\n",
    "        print(f\"\\nTraining {name}...\")\n",
    "        \n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', model)\n",
    "        ])\n",
    "        \n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_train_pred = pipeline.predict(X_train)\n",
    "        y_test_pred = pipeline.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "        test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "        \n",
    "        # Calculate precision, recall, and F1 score for each class\n",
    "        precision, recall, f1, support = precision_recall_fscore_support(y_test, y_test_pred, average='weighted')\n",
    "        \n",
    "        # Perform cross-validation\n",
    "        cv_scores = cross_val_score(pipeline, X, y, cv=cv, scoring='accuracy')\n",
    "        \n",
    "        results[name] = {\n",
    "            'Train Accuracy': train_accuracy,\n",
    "            'Test Accuracy': test_accuracy,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1 Score': f1,\n",
    "            'CV Accuracy Mean': cv_scores.mean(),\n",
    "            'CV Accuracy Std': cv_scores.std()\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nDetailed Classification Report for {name}:\")\n",
    "        print(classification_report(y_test, y_test_pred, \n",
    "                                 target_names=le.classes_,\n",
    "                                 zero_division=0))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error training {name}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "# Print results\n",
    "if results:\n",
    "    print(\"\\nModel Comparison Results:\")\n",
    "    print(\"-\" * 140)\n",
    "    print(f\"{'Model':<20} {'Train Acc':>10} {'Test Acc':>10} {'Precision':>10} {'Recall':>10} \"\n",
    "          f\"{'F1 Score':>10} {'CV Mean':>10} {'CV Std':>10}\")\n",
    "    print(\"-\" * 140)\n",
    "\n",
    "    for model_name, metrics in results.items():\n",
    "        print(f\"{model_name:<20} {metrics['Train Accuracy']:>10.4f} {metrics['Test Accuracy']:>10.4f} \"\n",
    "              f\"{metrics['Precision']:>10.4f} {metrics['Recall']:>10.4f} {metrics['F1 Score']:>10.4f} \"\n",
    "              f\"{metrics['CV Accuracy Mean']:>10.4f} {metrics['CV Accuracy Std']:>10.4f}\")\n",
    "\n",
    "    # Find and use the best model (using F1 score instead of just accuracy)\n",
    "    best_model = max(results.items(), key=lambda x: x[1]['F1 Score'])\n",
    "    print(f\"\\nBest performing model: {best_model[0]}\")\n",
    "    print(f\"F1 Score: {best_model[1]['F1 Score']:.4f}\")\n",
    "    print(f\"Test Accuracy: {best_model[1]['Test Accuracy']:.4f}\")\n",
    "\n",
    "    # Save predictions for the best model\n",
    "    best_model_name = best_model[0]\n",
    "    best_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', models[best_model_name])\n",
    "    ])\n",
    "    best_pipeline.fit(X_train, y_train)\n",
    "    final_predictions = best_pipeline.predict(X_test)\n",
    "\n",
    "    # Convert numerical predictions back to fertilizer names\n",
    "    final_predictions_labels = le.inverse_transform(final_predictions)\n",
    "    y_test_labels = le.inverse_transform(y_test)\n",
    "\n",
    "    comparison_df = pd.DataFrame({\n",
    "        'Actual': y_test_labels,\n",
    "        'Predicted': final_predictions_labels,\n",
    "        'Correct': y_test_labels == final_predictions_labels\n",
    "    })\n",
    "    \n",
    "    print(\"\\nSample of Actual vs Predicted values:\")\n",
    "    print(comparison_df.head(10))\n",
    "    \n",
    "    # Print confusion matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    cm = confusion_matrix(y_test_labels, final_predictions_labels)\n",
    "    print(pd.DataFrame(cm, index=le.classes_, columns=le.classes_))\n",
    "\n",
    "    comparison_df.to_csv('fertilizer_predictions.csv', index=False)\n",
    "else:\n",
    "    print(\"\\nNo models were successfully trained! Check the error messages above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Logistic Regression...\n",
      "Classification Report for Logistic Regression:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "        10/10/2010       1.00      1.00      1.00         2\n",
      "        10/26/2026       1.00      0.70      0.82        10\n",
      "          14-14-14       1.00      1.00      1.00         4\n",
      "          14-35-14       0.79      1.00      0.88        11\n",
      "          15-15-15       1.00      1.00      1.00         2\n",
      "          17-17-17       1.00      1.00      1.00        11\n",
      "             20-20       1.00      1.00      1.00        11\n",
      "             28-28       1.00      1.00      1.00        14\n",
      "               DAP       0.82      1.00      0.90        28\n",
      "Potassium chloride       1.00      1.00      1.00         1\n",
      "Potassium sulfate.       0.00      0.00      0.00         3\n",
      "    Superphosphate       0.00      0.00      0.00         1\n",
      "               TSP       0.67      0.50      0.57         8\n",
      "              Urea       1.00      0.96      0.98        25\n",
      "\n",
      "          accuracy                           0.91       131\n",
      "         macro avg       0.81      0.80      0.80       131\n",
      "      weighted avg       0.89      0.91      0.90       131\n",
      "\n",
      "\n",
      "Training Decision Tree...\n",
      "Classification Report for Decision Tree:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "        10/10/2010       1.00      1.00      1.00         2\n",
      "        10/26/2026       1.00      1.00      1.00        10\n",
      "          14-14-14       1.00      1.00      1.00         4\n",
      "          14-35-14       1.00      1.00      1.00        11\n",
      "          15-15-15       1.00      1.00      1.00         2\n",
      "          17-17-17       1.00      1.00      1.00        11\n",
      "             20-20       1.00      1.00      1.00        11\n",
      "             28-28       1.00      1.00      1.00        14\n",
      "               DAP       1.00      1.00      1.00        28\n",
      "Potassium chloride       1.00      1.00      1.00         1\n",
      "Potassium sulfate.       1.00      1.00      1.00         3\n",
      "    Superphosphate       1.00      1.00      1.00         1\n",
      "               TSP       1.00      1.00      1.00         8\n",
      "              Urea       1.00      1.00      1.00        25\n",
      "\n",
      "          accuracy                           1.00       131\n",
      "         macro avg       1.00      1.00      1.00       131\n",
      "      weighted avg       1.00      1.00      1.00       131\n",
      "\n",
      "\n",
      "Training Random Forest...\n",
      "Classification Report for Random Forest:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "        10/10/2010       1.00      1.00      1.00         2\n",
      "        10/26/2026       1.00      1.00      1.00        10\n",
      "          14-14-14       1.00      1.00      1.00         4\n",
      "          14-35-14       1.00      1.00      1.00        11\n",
      "          15-15-15       1.00      1.00      1.00         2\n",
      "          17-17-17       1.00      1.00      1.00        11\n",
      "             20-20       1.00      1.00      1.00        11\n",
      "             28-28       1.00      1.00      1.00        14\n",
      "               DAP       1.00      1.00      1.00        28\n",
      "Potassium chloride       1.00      1.00      1.00         1\n",
      "Potassium sulfate.       1.00      1.00      1.00         3\n",
      "    Superphosphate       1.00      1.00      1.00         1\n",
      "               TSP       1.00      1.00      1.00         8\n",
      "              Urea       1.00      1.00      1.00        25\n",
      "\n",
      "          accuracy                           1.00       131\n",
      "         macro avg       1.00      1.00      1.00       131\n",
      "      weighted avg       1.00      1.00      1.00       131\n",
      "\n",
      "\n",
      "Training Gradient Boosting...\n",
      "Classification Report for Gradient Boosting:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "        10/10/2010       1.00      1.00      1.00         2\n",
      "        10/26/2026       1.00      1.00      1.00        10\n",
      "          14-14-14       1.00      1.00      1.00         4\n",
      "          14-35-14       1.00      1.00      1.00        11\n",
      "          15-15-15       1.00      1.00      1.00         2\n",
      "          17-17-17       1.00      1.00      1.00        11\n",
      "             20-20       1.00      1.00      1.00        11\n",
      "             28-28       1.00      1.00      1.00        14\n",
      "               DAP       1.00      1.00      1.00        28\n",
      "Potassium chloride       1.00      1.00      1.00         1\n",
      "Potassium sulfate.       1.00      1.00      1.00         3\n",
      "    Superphosphate       1.00      1.00      1.00         1\n",
      "               TSP       1.00      1.00      1.00         8\n",
      "              Urea       1.00      1.00      1.00        25\n",
      "\n",
      "          accuracy                           1.00       131\n",
      "         macro avg       1.00      1.00      1.00       131\n",
      "      weighted avg       1.00      1.00      1.00       131\n",
      "\n",
      "\n",
      "Training XGBoost...\n",
      "Classification Report for XGBoost:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "        10/10/2010       1.00      1.00      1.00         2\n",
      "        10/26/2026       1.00      1.00      1.00        10\n",
      "          14-14-14       1.00      1.00      1.00         4\n",
      "          14-35-14       1.00      1.00      1.00        11\n",
      "          15-15-15       1.00      1.00      1.00         2\n",
      "          17-17-17       1.00      1.00      1.00        11\n",
      "             20-20       1.00      1.00      1.00        11\n",
      "             28-28       1.00      1.00      1.00        14\n",
      "               DAP       1.00      1.00      1.00        28\n",
      "Potassium chloride       1.00      1.00      1.00         1\n",
      "Potassium sulfate.       1.00      1.00      1.00         3\n",
      "    Superphosphate       1.00      1.00      1.00         1\n",
      "               TSP       1.00      1.00      1.00         8\n",
      "              Urea       1.00      1.00      1.00        25\n",
      "\n",
      "          accuracy                           1.00       131\n",
      "         macro avg       1.00      1.00      1.00       131\n",
      "      weighted avg       1.00      1.00      1.00       131\n",
      "\n",
      "\n",
      "Training SVC...\n",
      "Classification Report for SVC:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "        10/10/2010       1.00      1.00      1.00         2\n",
      "        10/26/2026       1.00      1.00      1.00        10\n",
      "          14-14-14       1.00      1.00      1.00         4\n",
      "          14-35-14       1.00      1.00      1.00        11\n",
      "          15-15-15       1.00      1.00      1.00         2\n",
      "          17-17-17       1.00      1.00      1.00        11\n",
      "             20-20       1.00      1.00      1.00        11\n",
      "             28-28       1.00      1.00      1.00        14\n",
      "               DAP       0.97      1.00      0.98        28\n",
      "Potassium chloride       0.00      0.00      0.00         1\n",
      "Potassium sulfate.       1.00      0.67      0.80         3\n",
      "    Superphosphate       0.00      0.00      0.00         1\n",
      "               TSP       0.80      1.00      0.89         8\n",
      "              Urea       1.00      0.96      0.98        25\n",
      "\n",
      "          accuracy                           0.97       131\n",
      "         macro avg       0.84      0.83      0.83       131\n",
      "      weighted avg       0.97      0.97      0.97       131\n",
      "\n",
      "\n",
      "Model Comparison Results:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model                 Train Accuracy   Test Accuracy CV Accuracy Mean CV Accuracy Std\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Logistic Regression           0.9596          0.9084          0.9170          0.0450\n",
      "Decision Tree                 1.0000          1.0000          1.0000          0.0000\n",
      "Random Forest                 1.0000          1.0000          1.0000          0.0000\n",
      "Gradient Boosting             1.0000          1.0000          1.0000          0.0000\n",
      "XGBoost                       1.0000          1.0000          1.0000          0.0000\n",
      "SVC                           0.9769          0.9695          0.9370          0.0172\n",
      "\n",
      "Best performing model: Decision Tree\n",
      "Test Accuracy: 1.0000\n",
      "\n",
      "Sample of Actual vs Predicted values:\n",
      "               Actual           Predicted  Correct\n",
      "0          10/26/2026          10/26/2026     True\n",
      "1                 DAP                 DAP     True\n",
      "2  Potassium chloride  Potassium chloride     True\n",
      "3            14-35-14            14-35-14     True\n",
      "4               28-28               28-28     True\n",
      "5            17-17-17            17-17-17     True\n",
      "6  Potassium sulfate.  Potassium sulfate.     True\n",
      "7          10/26/2026          10/26/2026     True\n",
      "8                 DAP                 DAP     True\n",
      "9                 DAP                 DAP     True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\rushi\\\\Desktop\\\\FertilizeWise\\\\FertWiseMergedMain.csv\") \n",
    "# First, identify categorical and numerical columns\n",
    "categorical_columns = ['Soil_Type', 'Crop_Type']\n",
    "numerical_columns = ['Temparature', 'Humidity', 'Moisture', 'Nitrogen', 'Potassium', 'Phosphorous']\n",
    "\n",
    "# Create preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_columns),\n",
    "        ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_columns)\n",
    "    ])\n",
    "\n",
    "# Prepare X and y\n",
    "# Convert target variable to numerical using LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df['Fertilizer'])\n",
    "X = df[numerical_columns + categorical_columns]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define classification models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'XGBoost': XGBClassifier(n_estimators=100, random_state=42),\n",
    "    'SVC': SVC(kernel='rbf')\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    try:\n",
    "        print(f\"\\nTraining {name}...\")\n",
    "        \n",
    "        # Create pipeline\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', model)\n",
    "        ])\n",
    "        \n",
    "        # Fit the pipeline\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_train_pred = pipeline.predict(X_train)\n",
    "        y_test_pred = pipeline.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "        test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "        \n",
    "        # Perform cross-validation\n",
    "        cv_scores = cross_val_score(pipeline, X, y, cv=5, scoring='accuracy')\n",
    "        \n",
    "        results[name] = {\n",
    "            'Train Accuracy': train_accuracy,\n",
    "            'Test Accuracy': test_accuracy,\n",
    "            'CV Accuracy Mean': cv_scores.mean(),\n",
    "            'CV Accuracy Std': cv_scores.std()\n",
    "        }\n",
    "        \n",
    "        print(f\"Classification Report for {name}:\")\n",
    "        print(classification_report(y_test, y_test_pred, \n",
    "                                 target_names=le.classes_))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error training {name}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "# Print results\n",
    "if results:\n",
    "    print(\"\\nModel Comparison Results:\")\n",
    "    print(\"-\" * 100)\n",
    "    print(f\"{'Model':<20} {'Train Accuracy':>15} {'Test Accuracy':>15} \"\n",
    "          f\"{'CV Accuracy Mean':>15} {'CV Accuracy Std':>15}\")\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "    for model_name, metrics in results.items():\n",
    "        print(f\"{model_name:<20} {metrics['Train Accuracy']:>15.4f} \"\n",
    "              f\"{metrics['Test Accuracy']:>15.4f} {metrics['CV Accuracy Mean']:>15.4f} \"\n",
    "              f\"{metrics['CV Accuracy Std']:>15.4f}\")\n",
    "\n",
    "    # Find and use the best model\n",
    "    best_model = max(results.items(), key=lambda x: x[1]['Test Accuracy'])\n",
    "    print(f\"\\nBest performing model: {best_model[0]}\")\n",
    "    print(f\"Test Accuracy: {best_model[1]['Test Accuracy']:.4f}\")\n",
    "\n",
    "    # Save predictions for the best model\n",
    "    best_model_name = best_model[0]\n",
    "    best_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', models[best_model_name])\n",
    "    ])\n",
    "    best_pipeline.fit(X_train, y_train)\n",
    "    final_predictions = best_pipeline.predict(X_test)\n",
    "\n",
    "    # Convert numerical predictions back to fertilizer names\n",
    "    final_predictions_labels = le.inverse_transform(final_predictions)\n",
    "    y_test_labels = le.inverse_transform(y_test)\n",
    "\n",
    "    comparison_df = pd.DataFrame({\n",
    "        'Actual': y_test_labels,\n",
    "        'Predicted': final_predictions_labels,\n",
    "        'Correct': y_test_labels == final_predictions_labels\n",
    "    })\n",
    "    \n",
    "    print(\"\\nSample of Actual vs Predicted values:\")\n",
    "    print(comparison_df.head(10))\n",
    "\n",
    "    comparison_df.to_csv('fertilizer_predictions.csv', index=False)\n",
    "else:\n",
    "    print(\"\\nNo models were successfully trained! Check the error messages above.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
